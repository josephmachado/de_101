{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f0caf4-cb3b-449f-ac76-a7d05d8cb3e1",
   "metadata": {},
   "source": [
    "# Data pipelines involves extracting, transforming, & loading data for analytical use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05375d-1f03-4d51-9586-6f80e3045ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../setup.py --db_file tpch.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87bc59c-72f6-48f2-a67e-32214cae9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext sql\n",
    "conn = duckdb.connect(\"tpch.db\")\n",
    "%sql conn --alias duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136b027-2f49-4fd8-b4bf-2f4ce6187b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "show tables;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e577c-2caf-4af6-9138-9c16fae32c36",
   "metadata": {},
   "source": [
    "## Let's create our data pipeline with Python\n",
    "\n",
    "We saw how to run SQL queries with Python \n",
    "We saw how to model our tables into bronze, silver & gold \n",
    "\n",
    "Let's put it together to be able to run the pipeline as a single function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe35b7-fe99-4d80-b0a4-999d98d1081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14afff3-7322-479a-afdf-22265faa6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bronze tables\n",
    "def create_bronze_tables(db_file_name):\n",
    "    with duckdb.connect(db_file_name) as con:\n",
    "        con.sql(\"\"\"\n",
    "        DROP SCHEMA IF EXISTS bronze CASCADE;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS bronze.customer;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE bronze.customer AS \n",
    "        SELECT \n",
    "            c_custkey AS customer_key,\n",
    "            c_name AS name,\n",
    "            c_address AS address,\n",
    "            c_nationkey AS nationkey,\n",
    "            c_phone AS phone,\n",
    "            c_acctbal AS acctbal,\n",
    "            c_mktsegment AS mktsegment,\n",
    "            c_comment AS comment\n",
    "        FROM customer;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS bronze.nation;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE bronze.nation AS \n",
    "        SELECT \n",
    "            n_nationkey AS nationkey,\n",
    "            n_name AS name,\n",
    "            n_regionkey AS regionkey,\n",
    "            n_comment AS comment\n",
    "        FROM nation;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS bronze.region;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE bronze.region AS \n",
    "        SELECT \n",
    "            r_regionkey AS regionkey,\n",
    "            r_name AS name,\n",
    "            r_comment AS comment\n",
    "        FROM region;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS bronze.orders;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE bronze.orders AS \n",
    "        SELECT \n",
    "            o_orderkey AS orderkey,\n",
    "            o_custkey AS custkey,\n",
    "            o_orderstatus AS orderstatus,\n",
    "            o_totalprice AS totalprice,\n",
    "            o_orderdate AS orderdate,\n",
    "            o_orderpriority AS orderpriority,\n",
    "            o_clerk AS clerk,\n",
    "            o_shippriority AS shippriority,\n",
    "            o_comment AS comment\n",
    "        FROM orders;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS bronze.lineitem;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE bronze.lineitem AS \n",
    "        SELECT \n",
    "            l_orderkey AS orderkey,\n",
    "            l_partkey AS partkey,\n",
    "            l_suppkey AS suppkey,\n",
    "            l_linenumber AS linenumber,\n",
    "            l_quantity AS quantity,\n",
    "            l_extendedprice AS extendedprice,\n",
    "            l_discount AS discount,\n",
    "            l_tax AS tax,\n",
    "            l_returnflag AS returnflag,\n",
    "            l_linestatus AS linestatus,\n",
    "            l_shipdate AS shipdate,\n",
    "            l_commitdate AS commitdate,\n",
    "            l_receiptdate AS receiptdate,\n",
    "            l_shipinstruct AS shipinstruct,\n",
    "            l_shipmode AS shipmode,\n",
    "            l_comment AS comment\n",
    "        FROM lineitem;\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c731cd-50bd-412c-8812-e713d58ee20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create silver tables\n",
    "def create_silver_tables(db_file_name):\n",
    "    with duckdb.connect(db_file_name) as con:\n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS dim_customer;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE dim_customer AS\n",
    "        SELECT \n",
    "            c.customer_key,\n",
    "            c.name AS customer_name,\n",
    "            c.address,\n",
    "            c.phone,\n",
    "            c.acctbal,\n",
    "            c.mktsegment,\n",
    "            n.name AS nation_name,\n",
    "            n.comment AS nation_comment,\n",
    "            r.name AS region_name,\n",
    "            r.comment AS region_comment\n",
    "        FROM bronze.customer AS c\n",
    "        LEFT JOIN bronze.nation AS n ON c.nationkey = n.nationkey\n",
    "        LEFT JOIN bronze.region AS r ON n.regionkey = r.regionkey;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS fct_orders;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE fct_orders AS\n",
    "        SELECT \n",
    "            o.orderkey,\n",
    "            o.custkey,\n",
    "            o.orderstatus,\n",
    "            o.totalprice,\n",
    "            o.orderdate,\n",
    "            o.orderpriority,\n",
    "            o.clerk,\n",
    "            o.shippriority,\n",
    "            o.comment\n",
    "        FROM bronze.orders AS o;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS fct_lineitem;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE fct_lineitem AS\n",
    "        SELECT \n",
    "            l.orderkey,\n",
    "            l.partkey,\n",
    "            l.suppkey,\n",
    "            l.linenumber,\n",
    "            l.quantity,\n",
    "            l.extendedprice,\n",
    "            l.discount,\n",
    "            l.tax,\n",
    "            l.returnflag,\n",
    "            l.linestatus,\n",
    "            l.shipdate,\n",
    "            l.commitdate,\n",
    "            l.receiptdate,\n",
    "            l.shipinstruct,\n",
    "            l.shipmode,\n",
    "            l.comment\n",
    "        FROM bronze.lineitem AS l;\n",
    "        \"\"\")\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b36280-096d-4f55-b54b-0f7ed4ac2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gold tables\n",
    "def create_obts(db_file_name):\n",
    "    with duckdb.connect(db_file_name) as con:\n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS wide_orders;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE wide_orders AS\n",
    "        SELECT o.*,\n",
    "            c.*\n",
    "        FROM fct_orders o\n",
    "        LEFT JOIN dim_customer c \n",
    "        ON o.custkey = c.customer_key;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS wide_lineitem;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE wide_lineitem AS\n",
    "        SELECT * FROM fct_lineitem;\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "def create_preagg_tables(db_file_name):\n",
    "    with duckdb.connect(db_file_name) as con:\n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS order_lineitem_metrics;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE order_lineitem_metrics AS\n",
    "        SELECT \n",
    "            orderkey AS order_key,\n",
    "            COUNT(linenumber) AS num_lineitems\n",
    "        FROM wide_lineitem\n",
    "        GROUP BY orderkey;\n",
    "        \"\"\")\n",
    "        con.sql(\"\"\"\n",
    "        DROP TABLE IF EXISTS customer_outreach_metrics;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.sql(\"\"\"\n",
    "        CREATE TABLE customer_outreach_metrics AS\n",
    "        SELECT \n",
    "            o.customer_key,\n",
    "            o.customer_name,\n",
    "            MIN(o.totalprice) AS min_order_value,\n",
    "            MAX(o.totalprice) AS max_order_value,\n",
    "            AVG(o.totalprice) AS avg_order_value,\n",
    "            AVG(m.num_lineitems) AS avg_num_items_per_order\n",
    "        FROM wide_orders AS o\n",
    "        LEFT JOIN (\n",
    "            SELECT \n",
    "                orderkey AS order_key,\n",
    "                COUNT(linenumber) AS num_lineitems\n",
    "            FROM wide_lineitem\n",
    "            GROUP BY orderkey\n",
    "        ) AS m ON o.orderkey = m.order_key\n",
    "        GROUP BY o.customer_key, o.customer_name;\n",
    "        \"\"\")\n",
    "\n",
    "def create_gold_tables(db_file_name):\n",
    "    create_obts(db_file_name)\n",
    "    create_preagg_tables(db_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6329e-4a6c-4560-bae8-a20577821849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(db_file_name):\n",
    "    print(\"==========CREATING BRONZE TABLES===================\")\n",
    "    create_bronze_tables(db_file_name)\n",
    "    print(\"==========CREATING SILVER TABLES===================\")\n",
    "    create_silver_tables(db_file_name)\n",
    "    print(\"==========CREATING GOLD TABLES===================\")\n",
    "    create_gold_tables(db_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1774053-85e9-4cb1-b0ba-a072f56d1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data pipeline \n",
    "db_file_name = './tpch.db'\n",
    "run_pipeline(db_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32883b42-d68c-419a-bbc9-eb95f71ce293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(db_file_name) as con:\n",
    "    con.table(\"customer_outreach_metrics\").show(max_rows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78475cc9-0797-44bb-890e-b6fbc66788ec",
   "metadata": {},
   "source": [
    "Cons\n",
    "\n",
    "* Code\n",
    "* Bugs and maintanance\n",
    "* adding new tables is tough\n",
    "* need to split out table functions for modularity,\n",
    "\n",
    "Just running SQL code, there is an easier way to do this with data build tool (dbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac03ce5-eaed-474f-ab82-e5e2819f8271",
   "metadata": {},
   "source": [
    "## dbt (data build tool) enables one to build data pipelines with SWE best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b9126-6c84-49e9-b608-9dd6821670ba",
   "metadata": {},
   "source": [
    "### dbt is a cli "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b7007-0514-44db-b1dd-2cce43b68e7f",
   "metadata": {},
   "source": [
    "- One SQL select query (with any transformations you want) per file\n",
    "- file name = model name (model can be SQL table/view/matreilaized view, etc)\n",
    "- Data quality checks\n",
    "- define documentation with yml file\n",
    "- automatic data lineage diagram with a static webpage\n",
    "- support for SCD2 creation\n",
    "- reusable macros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e32c19-e334-4f3d-9bda-45c406bde438",
   "metadata": {},
   "source": [
    "### The popularity of dbt is its ability to create data pipelines with SQL scripts\n",
    "\n",
    "dbt recommends the following folder structure\n",
    "* `models/staging`: bronze data\n",
    "* `models/intermediate`: silver data\n",
    "* `models/marts`: gold data (both obt and pre-agg table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896cc7d-87d0-483b-b55b-d914fd42f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "! dbt --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5745f0-f66a-4973-88d4-55da408021be",
   "metadata": {},
   "outputs": [],
   "source": [
    "! dbt init tpch_warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3888a0-94e5-4284-9bc5-cbc42c71a5f3",
   "metadata": {},
   "source": [
    "Create a `profiles.yml` in the `tpch_warehouse` folder with the following content (note this would be already created for you)\n",
    "\n",
    "```yml\n",
    "---\n",
    "config:\n",
    "  send_anonymous_usage_stats: false\n",
    "tpch_warehouse:\n",
    "  target: dev\n",
    "  outputs:\n",
    "    dev:\n",
    "      type: duckdb\n",
    "      path: ./dbt.duckdb\n",
    "    prod:\n",
    "      type: duckdb\n",
    "      path: ./dbt-prod.duckdb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd8e9d-93cf-40f3-a953-83575b41059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd tpch_warehouse/ && python ../../setup.py --db_file dbt.duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67515dc-48df-4cf2-a3ac-6b91db9b215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir tpch_warehouse/raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ee0df-28a7-469d-8297-59ec87449b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "db_file_name = './tpch_warehouse/dbt.duckdb'\n",
    "conn = duckdb.connect(db_file_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for table in ['customer', 'orders', 'lineitem', 'nation', 'region', 'supplier', 'part', 'partsupp']:\n",
    "    cursor.execute(f\"COPY {table} TO './tpch_warehouse/raw_data/{table}.csv' (HEADER, DELIMITER ',');\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8fcc5-eb55-4928-8aa9-6dd06b161c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd tpch_warehouse && dbt debug # Command to check connection to our warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cea369-53c6-43be-ab63-712acf683998",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ./tpch_warehouse/models/*/.ipynb_checkpoints # always run before dbt run, caused by notebooks, no need to do this if performed via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c0a8c-2d40-4ebb-9172-e356c9652ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd tpch_warehouse/ && dbt run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d319b-06a3-49db-825f-854a9ca8d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ./tpch_warehouse/models/*/.ipynb_checkpoints # always run before dbt test, caused by notebooks, no need to do this if performed via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977f862-b9c8-4d11-949d-0dea76662443",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd tpch_warehouse/ && dbt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4274d7-45d9-4000-9cab-3295db41f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "db_file_name = './tpch.db'\n",
    "conn = duckdb.connect(db_file_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Connect to DuckDB and load TPC-H tables into Pandas DataFrames\n",
    "customer_df = cursor.sql(\"SELECT * FROM dim_customer\").df()\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37311b-4b7c-46de-85ff-16c0e27dfda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a29dbb-2517-45d6-96a7-879e30e3eac4",
   "metadata": {},
   "source": [
    "### dbt has a preferred step-by-step way to transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f82d6-9525-4400-bc52-e343dca060df",
   "metadata": {},
   "source": [
    "### Connection credentials are stored in profiles.yml\n",
    "\n",
    "The file at `tpch_warehouse/profiles.yml` has information about the different environment credentials. In real life projects you'd use environment variables (add:link) or have a service (e.g. aws secrets) to store production credentials.\n",
    "\n",
    "```yml\n",
    "---\n",
    "config:\n",
    "  send_anonymous_usage_stats: false\n",
    "tpch_warehouse: # project name\n",
    "  target: dev\n",
    "  outputs:\n",
    "    dev:\n",
    "      type: duckdb\n",
    "      path: ./dbt.duckdb\n",
    "    prod:\n",
    "      type: duckdb\n",
    "      path: ./dbt-prod.duckdb\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1498d-8924-40a8-93ed-20226db3ec42",
   "metadata": {},
   "source": [
    "### Configuration settings are stored in dbt_project.yml\n",
    "\n",
    "dbt's configuration settings are stored in`tpch_warehouse/dbt_project.yml`. Some of the configs here are\n",
    "\n",
    "* materialization: how should the sql model be saved as views/tables/materialized views, etc\n",
    "* You can define configs as folder path (e.g. tpch_warehouse/models/marts/ can be tables)\n",
    "* Tell dbt where to look for models, seeds, snapshots, macros, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6675bc-28ec-4275-86d8-20ecbd098613",
   "metadata": {},
   "source": [
    "### Ensure the data is correct with tests\n",
    "\n",
    "We can define data quality for our models using its `yml` file, where we store data documentation. \n",
    "\n",
    "For e.g.\n",
    "\n",
    "```yml\n",
    "models:\n",
    "  - name: stg_customer\n",
    "    description: Customer data from the TPCH dataset with standardized column names for clarity.\n",
    "    columns:\n",
    "      - name: customer_key\n",
    "        description: The unique identifier for each customer.\n",
    "        data_tests:\n",
    "          - not_null\n",
    "          - unique\n",
    "```\n",
    "\n",
    "Here when we run `dbt test` the customer_key column in stg_customer table will be checked for uniqueness and not nulls.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
